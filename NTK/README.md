# NTK 

We have several notebooks in this part.

1. Effect of top layer scaling: alpha.ipynb
2. Effect of the number of layers: m.ipynb
3. Linear approximation: ntk_approx.ipynb
4. Factors to break NTK regime: 
    (1) learning rate: lr.ipynb; 
    (2) momentum: momentum.ipynb; 
    (3) feature weights initialization: theta_init.ipynb; 
